# المجزئ الجغرافي: ضبط نموذج تجزئة أي شيء ذو التلقينات متعددة الوسائط لتجزئة البنية التحتية للتنقل [←](../ArabicPaperReviews)

## الملخص

<SourceText original="In geographical image segmentation, performance is often constrained by the limited availability of training data and a lack of generalizability, particularly for segmenting mobility infrastructure such as roads, sidewalks, and crosswalks.">
يُقيد الأداء في مجال تجزئة الصور الجغرافية غالبًا بمحدودية بيانات التدريب ونقص القدرة على التعميم، لا سيما عند تجزئة البنية التحتية للمواصلات كالشوارع والأرصفة وممرات المشاة.
</SourceText>
<SourceText original="Vision foundation models like the Segment Anything Model (SAM), pre-trained on millions of natural images, have demonstrated impressive zero-shot segmentation performance, providing a potential solution.">
وقد أظهرت <abbr title="نموذج كبير للرؤية الحاسوبية وغير مرتبط بمهمة محددة، دُرب مسبقاً على صور متنوعة وواسعة النطاق، ويمكن تكييفه مع مهام جديدة دون إعادة تدريبه، بتوجييه بإستخدام التلقينات..">نماذج الرؤية الأساسية</abbr>، مثل نموذج <abbr title="نحت لكلمتي تجزئة أي شيء، هو نموذج أساسي في مجال الرؤية الحاسوبية من تطوير شركة ميتا، يدعى SAM - Segment Anything">التجشئة</abbr> المُدرّب مسبقًا على ملايين الصور الطبيعية، أداءً مذهلاً في <abbr title="هو تجزئة الكائنات أو الأجسام داخل الصور باستخدام النموذج مدرب مسبقاً بتلقينه ذلك فقط دون ذكر مثال مشابه للجسم المراد تجزئته في التوجيه ودون ضبط ذلك النموذج على مجموعة البيانات المستهدفة">التجزئة بدون مثال</abbr>، مما يُقدّم حلاً واعدًا.
</SourceText>
<SourceText original="However, SAM struggles with geographical images, such as aerial and satellite imagery, due to its training being confined to natural images and the narrow features and textures of these objects blending into their surroundings">لكن، يُواجه نموذج **التجشئة** صعوبةً في التعامل مع الصور الجغرافية، كصور الأقمار الصناعية والصور الجوية، نظرًا لاقتصار تدريب النموذج على الصور الطبيعية، وتداخل ملامح الأجسام وقوامها من الفضاء مع محيطها.</SourceText>
<SourceText original="To address these challenges, we propose Geographical SAM (GeoSAM), a SAM-based framework that fine-tunes SAM using automatically generated multi-modal prompts.">
يقترح الباحثون في هذه الورقة لمعالجة هذه التحديات، نموذج التجشئة الجغرافي، كإطار عمل قائم على نموذج تجشئة بأداء محسن باستخدام <abbr title="multi-modal prompts، تشير إلى الجمع بين أنواع التلقينات المختلفة كالجمع بين التلقينات النصية والتلقينات النقطية. سيستخدم هذا المصطلح بكثرة في هذه الورقة، حيث أن نموذج التجشئة الذي قام عليه العمل في هذه الورقة يقدم عدة أنواع من التلقينات وليست فقط التلقينات النصية المعروفة، إنما هناك أيضاً تلقين نقطي حيث يستطيع المستخدم تحديد نقطة واحدة على الكائن المراد تجزئته من الصورة، والتلقين القناع، حيث يستطيع المستخدم تلقين النموذج بمضلع حول الكائن المراد تجزئته، وأخير تلقين المربع حيث يستطيع رسم مربع على الكائن المراد تجزئته من الصورة، ليقوم نموذج التجشئة SAM باستخراج الكائن من الصورة.">تلقينات متعددة الوسائط</abbr> مولدة تلقائياً.
</SourceText>
<SourceText original="Specifically, GeoSAM integrates point prompts from a pre-trained taskspecific model as primary visual guidance, and text prompts generated by a large language model as secondary semantic guidance, enabling the model to better capture both spatial structure and contextual meaning.">
يدمج نموذج التجشئة الجغرافي التلقينات النقطية من نموذج مُدرّب مسبقًا خاص لهذه المهمة كدليل بصري أساسي، مع تلقينات نصية مُولّدة بواسطة نموذج لغوي كبير كدليل دلالي ثانوي، مما يُمكّن النموذج من استيعاب كلٍ من البنية المكانية والمعنى السياقي بشكل أفضل.
</SourceText>
<SourceText original="GeoSAM outperforms existing approaches for mobility infrastructure segmentation in both familiar and completely unseen regions by at least 5% in mIoU, representing a significant leap in leveraging foundation models to segment mobility infrastructure, including both road and pedestrian infrastructure in geographical images.">
يتفوق نموذج التجشئة الجغرافي على الأساليب الحالية في تجزئة بنية النقل التحتية في المناطق المألوفة وغير المألوفة بنسبة لا تقل عن 5% في مؤشر <abbr title="mIoU تُحسب الدقة في عملية التجزئة من قسمة تقاطع مضلعي الكائن الحقيقي في مجموعة البيانات، والمضلع الذي تنبأ بهذ النموذج على اتحاد المضلعين، فإذا كان على النموذج أن يتنبأ بأكثر من فئة لكل كائن استطاع تجزئته، عندها يحسب متوسط التقاطع على الاتحاد لكل الفئات.">متوسط التقاطع على الاتحاد</abbr>، مما يمثل قفزة نوعية في الاستفادة من النماذج الأساسية لتجزئة البنية التحتية للتنقل، بما في ذلك الطرق وممرات المشاة في الصور الجغرافية.
</SourceText>
<SourceText original="The source code is publicly available">
تم نشر كود النموذج للعموم [هنا](https://github.com/rafiibnsultan/GeoSAM).
</SourceText>


## المقدمة

<SourceText original="While a substantial amount of research [7, 43, 17, 28, 13] has focused on road infrastructure segmentation from geographical and remote sensing imagery like aerial and satellite images, pedestrian infrastructure, such as sidewalks or crosswalks, has received comparatively little attention, despite its importance in daily life.">
ركزت الكثير من الأبحاث [^7] [^43] [^17] [^28] [^13] على تجزئة البنية التحتية للطرق من الصور الجغرافية وصور الاستشعار عن بُعد، مثل الصور الجوية والفضائية، إلا أن البنية التحتية للمشاة، كالأرصفة وممرات عبور المشاة، لم تحظَ إلا باهتمام ضئيل نسبياً، رغم أهميتها في الحياة اليومية.
</SourceText>
<SourceText original="Historically, research efforts have predominantly focused on assisting drivers in navigation rather than pedestrians [^18].">
انصبّت الجهود البحثية تاريخياً على مساعدة السائقين في التنقل في الغالب بدلاً من مساعدة المشاة [^18].
</SourceText>
<SourceText original="Existing accessibility studies often use simplified road data, but accurate segmentation of pedestrian infrastructure can better reveal accessible routes and destinations, especially for people with disabilities.">
تستخدم دراسات <abbr title="تشير إلى قدرة المشاة وذوي الحاجات الخاصة على استخدام البنية التحتية والحضرية (الأرصفة، وممرات المشاة، والممرات) بأمان وفعالية.">إمكانية الوصول</abbr> الحالية غالباً بيانات طرق مبسطة، ونعلم أن التجزئة الدقيقة لبنية المشاة التحتية تُسهم في الكشف بشكل أفضل عن الطرق والوجهات المُيسّرة، لا سيما للأشخاص ذوي الإعاقة.
</SourceText>

<br />

![تجزئة البنية التحتية للتنقل: (أ) تحتاج النماذج التقليدية إلى مجموعات بيانات كبيرة خاصة بكل مهمة، (ب) وتواجه صعوبة في التعامل مع الكائنات الضيقة ذات النسيج المتشابه، مما ينتج عنه نتائج دون المستوى المطلوب. ويحقق ضبط نموذج أساسي قابل للتلقين باستخدام بيانات وتوجيهات محدودة أداءً مماثلاً.](./GeoSamFig1.jpg)
<SourceText original="Mobility infrastructure segmentation: (a) Traditional models need large task-specific datasets, (b) struggle with narrow, texture-similar objects, yielding subpar results.">
تجزئة البنية التحتية للتنقل: (أ) تحتاج النماذج التقليدية إلى مجموعات بيانات كبيرة خاصة بكل مهمة، (ب) وتواجه صعوبة في التعامل مع الكائنات الضيقة ذات النسيج المتشابه، مما ينتج عنه نتائج دون المستوى المطلوب.
</SourceText>
<SourceText original="Fine-tuning a promptable foundation model with limited data and prompts achieves on-par performance.">
ويحقق ضبط نموذج أساسي قابل للتلقين باستخدام بيانات وتوجيهات محدودة أداءً مماثلاً.
</SourceText>

<br />
<br />


<SourceText original="Rooted in historical context, mobility infrastructure segmentation has predominantly relied on traditional models, including Convolutional Neural Networks (CNNs) [31, 45, 20, 27] and Vision Transformer (ViT) models [14, 11].">
اعتمدت تاريخياً تجزئة البنية التحتية للتنقل بشكل أساسي على النماذج التقليدية، بما في ذلك الشبكات الطي العصبية [^31] [^45] [^20] [^27] ونماذج مُحوّل الرؤية [^14] [^11].
</SourceText>
<SourceText original="These models typically require large collections of human-labeled data for task-specific training [18, 3], something that is oftentimes a luxury for these tasks, and are often too sensitive to changes in data.">
تتطلب تلك النماذج عادةً مجموعات كبيرة من <abbr title="صور تم وضع أقنعة التجزئة حول الكائنات والأجسام وعناوين لتلك الكائنات أو الأجسام يدوياً بواسطة البشر، وهو أمر مكلف ويستغرق وقتاً طويلا مايجعله صعب التوسع.">الصور المعنونة يدوياً</abbr> للتدريب الخاص بكل مهمة [^18] [^3]، وهو أمرٌ غالبًا ما يكون ترفًا لهذه المهام، كما أنها غالبًا ما تكون شديدة الحساسية للتغيرات في البيانات.
</SourceText>
<SourceText original="However, the scarcity of high-quality labeled datasets remains a major challenge, especially in the context of mobility infrastructure, limiting scalability and adaptability to diverse tasks.">
ولا يزال نقص مجموعات البيانات المعنونة بجودة عالية يمثل تحديًا كبيرًا، لا سيما في سياق البنية التحتية للتنقل، مما يحد من قابلية التوسع والتكيف مع المهام المتنوعة.
</SourceText>

<br />

<SourceText original="Traditional models, when trained on limited and homogeneous datasets(Figure 1a), often fail to distinguish fine-grained classes such as sidewalks and roads, which exhibit subtle visual differences like thin boundaries, similar textures, and frequent occlusions (Figure 1b).">
تفشل النماذج التقليدية غالبًا، عند تدريبها على مجموعات بيانات محدودة ومتجانسة (الشكل 1a)، في التمييز بين الفئات الدقيقة (مثل الأرصفة والطرق)، والتي تُظهر اختلافات بصرية دقيقة (مثل الحدود الرقيقة، والنسيج المتشابه، والحجب المتكرر) (الشكل 1b).
</SourceText>
<SourceText original="Moreover, their learned representations are typically domain-specific, resulting in poor generalization when deployed in unseen regions or datasets with different visual characteristics.">
اوة على ذلك، فإن ما تعلمته تلك النماذج من تمثيلات للكائنات والأجسام عادةً ما تكون خاصة بمجال معين، ما يؤدي إلى ضعف التعميم عند استخدامها في مناطق غير مرئية أو مجموعات بيانات ذات خصائص بصرية مختلفة.
</SourceText>
<SourceText original="Even minor shifts in data distribution, such as moving from one geographic region to another, often lead to significant performance degradation.">
وحتى التحولات الطفيفة في توزيع البيانات، مثل الانتقال من منطقة جغرافية إلى أخرى، غالبًا ما تؤدي إلى تدهور كبير في الأداء.
</SourceText>
<SourceText original="In contrast, vision foundation models, pre-trained taskagnostically on large-scale and diverse image distributions [21, 26], offer a promising alternative with superior generalization ability
across varying domains.">
تُقدم - في المقابل - <abbr title="نموذج كبير للرؤية الحاسوبية وغير مرتبط بمهمة محددة، دُرب مسبقاً على صور متنوعة وواسعة النطاق، ويمكن تكييفه مع مهام جديدة دون إعادة تدريبه، بتوجييه بإستخدام التلقينات..">نماذج الرؤية الأساسية</abbr>، المُدربة مسبقًا بشكل مستقل عن المهمة على توزيعات صور متنوعة وواسعة النطاق [^21] [^26]، بديلاً واعدًا بقدرة تعميم فائقة (عبر مجالات متنوعة).
</SourceText>
<SourceText original="These models adapt to new downstream tasks without re-training, relying on user-provided prompts for contextual guidance.">
تتكيف هذه النماذج مع المهام اللاحقة الجديدة (دون الحاجة إلى إعادة التدريب)، معتمدةً على توجيهات المستخدم للإرشاد السياقي.
</SourceText>
<SourceText original="In this work, we leverage the Segment Anything Model (SAM) [21], a promptable vision foundation model, to overcome the limitations of traditional approaches and enable effective segmentation of mobility infrastructure, even with limited labeled data and across geographically diverse regions.">
استفاد الباحثون في هذه الورقة من نموذج **التجشئة** (تجزئة أي شيء) [^21]، وهو <abbr title="نموذج كبير للرؤية الحاسوبية وغير مرتبط بمهمة محددة، دُرب مسبقاً على صور متنوعة وواسعة النطاق، ويمكن تكييفه مع مهام جديدة دون إعادة تدريبه، بتوجييه بإستخدام التلقينات. (قمت بإستخدام صيغة النكرة لوجود العديد من تلك النماذج الأساسية).">نموذج رؤية أساسي</abbr> قابل للتوجيه، للتغلب على قيود الأساليب التقليدية وتمكين التجزئة الفعالة للبنية التحتية للتنقل، حتى مع البيانات المعنونة المحدودة وعبر مناطق جغرافية متنوعة.
</SourceText>

<br />

<SourceText original="However, unlike compact objects in natural images, where a single point (e.g., placed on a dog’s body) often suffices for segmentation, spatially extensive structures like roads and sidewalks usually require multiple iterative prompts to capture their full extent.">
تتطلب الهياكل واسعة النطاق مكانيًا، كالشوارع والأرصفة، عادةً عدة محاولات متكررة لالتقاط امتدادها الكامل، على عكس الأجسام الصغيرة في الصور الطبيعية، حيث تكفي نقطة واحدة (مثلاً، على جسم حصان) للتجزئته.
</SourceText>
<SourceText original="This process is often exhaustive and error-prone, and even with multiple prompts, zero-shot SAM struggles in remote sensing tasks due to its pre-training on natural images, which lack the large, texture-similar structures common in geographical data [21].">
هذه العملية مرهقة وعرضة للأخطاء غالباً، وحتى مع المحاولات المتعددة، سيواجه نموذج التجشئة بدون مثال صعوبة في مهام الاستشعار عن بعد نظراً لتدريبه المسبق على الصور الطبيعية، التي تفتقر إلى الهياكل الكبيرة ذات النسيج المتشابه الشائعة في البيانات الجغرافية [^21].
</SourceText>
<SourceText original="Nonetheless, SAM’s general segmentation capability can be adapted to geographical imagery via fine-tuning on limited data (bottom of Figure 1), allowing it to learn domain-specific patterns and remain effective under regional distribution shifts.">
نستطيع مع ذلك تكييف قدرة نموذج التجشئة على تجزئة الصور الجغرافية من خلال ضبطه بدقة على بيانات محدودة (أسفل الشكل 1)، ما يسمح له بتعلم أنماط خاصة بالمجال والحفاظ على فعاليته في ظل تغيرات التوزيع المكاني.
</SourceText>
<SourceText original="Capitalizing on this strength, we introduce Geographical SAM (GeoSAM), an end-to-end model tailored for segmenting mobility infrastructure through multi-class segmentation of road and pedestrian infrastructure.">
قدم الباحثون في هذه الورقة <abbr title="GeoSAM - Geographical Segment Anything هو نموذج تجشئة حيث أن فاك التشفير فيه مضبوط على صور الجغرافية باستخدام تلقينات نقطية ونصية آلية التوليد لتجزئة النبية التحتية للطرق والمشاة بدقة من الصور الجوية والفضائية.">نموذج التجشئة الجغرافي</abbr> بالاستفادة من تلك الميزة، وهو نموذج شامل مصمم لتجزئة البنية التحتية للتنقل من خلال تجزئة متعددة الفئات للطرق والنبية التحتية للمشاة.
</SourceText>

<br />

<SourceText original="To address these challenges, we propose Geo-Point Generation (GPG), an automated prompt generation technique that generates point prompts for geographical images from a domain-specific pretrained model for precise spatial guidance.">
يقترح الباحثون في هذه الورقة تقنية <abbr title="طريقة للتوليد التلقائي للتلقينات النقطية التي تشير إما إلى عنصر جغرافي على الصور foreground أو إلى خلفية الصورة background وذلك باستخدام نموذج تجزئة تقليدي مدرب مسبقاً لهذه الوظيفة فقط.">توليد النقاط الجغرافية</abbr> لمعالجة التحديات السابقة، وهي تقنية تولد تلقينات نقطية آلياً للصور الجغرافية من نموذج مُدرَّب مسبقًا خاص بمجال الصور الجغرافي، وذلك لتوفير توجيه مكاني دقيق.
</SourceText>
<SourceText original="It is complemented by text prompts for semantic clarity to resolve ambiguities inherent in pointbased guidance.">
وتُكمَّل هذه التقنية بتلقينات نصية لتوضيح المعنى الدلالي وحل الغموض الكامن في التوجيه القائم على النقاط.
</SourceText>
<SourceText original="Point prompts focus the model on specific pixels, but a single pixel can often belong to multiple objects.">
تلفت التلقينات النقطية تركيز النموذج على بكسلات مُحدَّدة، لكن غالباً ما ينتمي بكسل واحد على الصور إلى عدة كائنات.
</SourceText>
<SourceText original="Text prompts, containing semantic information about the class, clarify the object of interest and provide a broader understanding [37].">
فتأتي التلقينات النصية، والتي تحتوي على معلومات دلالية حول صنف الكائن، لتقدم فهماً أوسع للكائن محل الاهتمام [^37].
</SourceText>
<SourceText original="This complementary design ensures precise geometrical guidance from point prompts and broader contextual understanding from text prompts, enhancing segmentation accuracy.">
يضمن هذا التصميم المتكامل توجيهًا هندسيًا دقيقًا من التلقينات النقطية وفهمًا سياقيًا أوسع من التلقينات النصية، ما يُحسِّن دقة التجزئة.
</SourceText>

<br />

<SourceText original="These multi-modal prompts fine-tune SAM through its lightweight decoder.">
تضبط <abbr title="multi-modal prompts، تشير إلى الجمع بين أنواع التلقينات المختلفة كالجمع بين التلقينات النصية والتلقينات النقطية. سيستخدم هذا المصطلح بكثرة في هذه الورقة، حيث أن نموذج التجشئة الذي قام عليه العمل في هذه الورقة يقدم عدة أنواع من التلقينات وليست فقط التلقينات النصية المعروفة، إنما هناك أيضاً تلقين نقطي حيث يستطيع المستخدم تحديد نقطة واحدة على الكائن المراد تجزئته من الصورة، والتلقين القناع، حيث يستطيع المستخدم تلقين النموذج بمضلع حول الكائن المراد تجزئته، وأخير تلقين المربع حيث يستطيع رسم مربع على الكائن المراد تجزئته من الصورة، ليقوم نموذج التجشئة SAM باستخراج الكائن من الصورة.">التلقينات متعددة الوسائط</abbr> نموذج <abbr title="نحت لكلمتي تجزئة أي شيء، هو نموذج أساسي في مجال الرؤية الحاسوبية من تطوير شركة ميتا، يدعى SAM - Segment Anything">التجشئة</abbr> من خلال وحدة فك التشفير.
</SourceText>
<SourceText original="By integrating spatial precision with semantic context, we introduce Geographical SAM (GeoSAM), an end-to-end SAMbased model fine-tuned for multi-class segmentation of roads and pedestrian infrastructure.">
قدم الباحثون في هذه الورقة <abbr title="GeoSAM - Geographical Segment Anything هو نموذج تجشئة (تجزئة أي شيء) حيث أن فاك التشفير مضبوط على صور الجغرافية باستخدام تلقينات نقطية ونصية آلية التوليد لتجزئة البنية التحتية للطرق والمشاة بدقة من الصور الجوية والفضائية.">المجشئ الجغرافي</abbr> من خلال دمج الدقة المكانية (عبر التلقين النقطي على الصورة) والسياق المكاني (عبر التلقين النصي الذي يصف الكائن)، كنموذج <abbr title="نحت لكلمتي تجزئة أي شيء، هو نموذج أساسي في مجال الرؤية الحاسوبية من تطوير شركة ميتا، يدعى SAM - Segment Anything">التجشئة</abbr> متكامل مُحسَّن لتجزئة الطرق والبنية التحتية للمشاة إلى فئات متعددة.
</SourceText>
<SourceText original="GeoSAM outperforms traditional CNNbased approaches [18, 17, 43], not only improving segmentation accuracy but also demonstrating the potential of combining natural language and visual interaction within foundation models for geographical imagery.">
يتفوق <abbr title="GeoSAM - Geographical Segment Anything هو نموذج تجشئة (تجزئة أي شيء) حيث أن فاك التشفير مضبوط على صور الجغرافية باستخدام تلقينات نقطية ونصية آلية التوليد لتجزئة البنية التحتية للطرق والمشاة بدقة من الصور الجوية والفضائية.">المجشئ الجغرافي</abbr> على الأساليب التقليدية القائمة على شبكات الطي العصبية [^18] [^17] [^43]، ليس فقط بتحسين دقة التجزئة، بل أيضًا بإظهار إمكانية دمج اللغة الطبيعية والتفاعل المرئي ضمن <abbr title="نموذج كبير للرؤية الحاسوبية وغير مرتبط بمهمة محددة، دُرب مسبقاً على صور متنوعة وواسعة النطاق، ويمكن تكييفه مع مهام جديدة دون إعادة تدريبه، بتوجييه بإستخدام التلقينات.">النماذج الأساسية</abbr> للصور الجغرافية.
</SourceText>
<SourceText original="">تتلخص إسهامات الباحثون في ثلاثة جوانب: (1) الريادة في استخدام <abbr title="نحت لكلمتي تجزئة أي شيء، هو نموذج أساسي في مجال الرؤية الحاسوبية من تطوير شركة ميتا، يدعى SAM - Segment Anything">المجشئ</abbr> لتجزئة البنية التحتية للتنقل إلى فئات متعددة، من خلال دمج التلقينات النقطية والنصية في الصور الجغرافية.</SourceText>
<SourceText original="(2) We introduce fine-tuning and automated prompt generation techniques that inject domain knowledge from traditional models via multi-modal prompts.">
(2) تقديم تقنيات ضبط النماذج وتوليد التلقينات تلقائيًا، والتي تجلب المعرفة المتخصصة من النماذج التقليدية إلى النماذج الأساسية عبر التلقينات متعددة الوسائط.
</SourceText>
<SourceText original="(3) We conduct extensive evaluations on datasets from two cities, demonstrating GeoSAM’s strong performance and generalizability across diverse locations.">
(3) إجراء تقييم شامل على مجموعات بيانات مدينتين، ما أظهر الأداء القوي لنموذج التجشئة الجغرافي وقابليته للتعميم عبر مواقع متنوعة.
</SourceText>

## المراجع
[^3]: K. Cha, J. Seo, and T. Lee. A billion-scale foundation model for remote sensing images. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2024.

[^7]: X. Chen, Q. Sun,W. Guo, C. Qiu, and A. Yu. Ga-net: A geometry prior assisted neural network for road extraction. International Journal of Applied Earth Observation and Geoinformation, 114:103004, 2022.
[^11]: A. Dosovitskiy et al. An image is worth 16x16 words: Transformers for image recognition at scale. In ICLR, 2021.
[^13]: P. Gudžius, O. Kurasova, V. Darulis, and E. Filatovas. Deep learning based object recognition in multispectral satellite imagery for real-time applications. Machine Vision and Applications, 32(4):98, 2021.
[^14]: A. Hatamizadeh, V. Nath, Y. Tang, D. Yang, H. R. Roth, and D. Xu. Swin unetr: Swin transformers for semantic segmentation of brain tumors in mri images. In International MICCAI Brainlesion Workshop, pages 272–284. Springer, 2021.
[^17]: C. Henry, S. M. Azimi, and N. Merkle. Road segmentation in sar satellite images with deep fully convolutional neural networks. IEEE Geoscience and Remote Sensing Letters, 15(12):1867–1871, 2018.
[^18]: M. Hosseini, A. Sevtsuk, F. Miranda, R. M. Cesar Jr, and C. T. Silva. Mapping the walk: A scalable computer vision approach for generating sidewalk network datasets from aerial imagery. Computers, Environment and Urban Systems, 101:101950, 2023.
[^20]: F. Isensee, P. F. Jaeger, S. A. Kohl, J. Petersen, and K. H. Maier-Hein. nnu-net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2):203–211, 2021.
[^21]: A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo, et al. Segment anything. In Proceedings of the IEEE/CVF International Conference on
Computer Vision, pages 4015–4026, 2023.
[^26]: A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al. Learning transferable visual models from natural language supervision. In International conference
on machine learning, pages 8748–8763. PMLR, 2021.
[^27]: O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015. Springer, 2015.
[^28]: A. Saha. Conducting semantic segmentation on landcover satellite imagery through u-net architectures. In Proceedings of the Future Technologies Conference, pages 758–764. Springer, 2022.
[^31]: K. Sun, B. Xiao, D. Liu, and J. Wang. Deep high-resolution representation learning for human pose estimation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019.
[^37]: Y. Yan, H. Wen, S. Zhong, W. Chen, H. Chen, Q. Wen, R. Zimmermann, and Y. Liang. Urbanclip: Learning text-enhanced urban region profiling with contrastive language-image pretraining from the web. In Proceedings of the ACM on Web Conference 2024, 2024.
[^43]: L. Zhou, C. Zhang, and M. Wu. D-linknet: Linknet with pretrained encoder and dilated convolution for high resolution satellite imagery road extraction. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 182–186, 2018.
[^45]: Z. Zhou, M. M. Rahman Siddiquee, N. Tajbakhsh, and J. Liang. Unet++: A nested u-net architecture for medical image segmentation. In Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pages 3–11. Springer, 2018.

